{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ExpenseFlow - Multi-Agent Budget Analysis System","text":""},{"location":"#overview","title":"Overview","text":"<p>ExpenseFlow is an intelligent expense analysis system powered by a 4-agent architecture and local LLM models (Ollama). It automatically classifies expenses, researches market prices, analyzes spending patterns, and generates personalized financial recommendations.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#multi-agent-architecture","title":"\ud83e\udd16 Multi-Agent Architecture","text":"<ul> <li>4 specialized agents working in orchestrated pipeline</li> <li>Each agent has single responsibility (SRP)</li> <li>Clean separation of concerns</li> </ul>"},{"location":"#intelligent-model-selection","title":"\ud83c\udfaf Intelligent Model Selection","text":"<ul> <li>Task-based model routing: Fast model for simple tasks, accurate model for complex reasoning</li> <li>3x faster response times for classification and analysis</li> <li>Better quality recommendations</li> </ul>"},{"location":"#automated-price-research","title":"\ud83d\udd0d Automated Price Research","text":"<ul> <li>Web search integration via DuckDuckGo</li> <li>Automatically researches high-value items (\u2265100 TL)</li> <li>Handles unparsed prices (amount = 0.0)</li> </ul>"},{"location":"#financial-analysis","title":"\ud83d\udcca Financial Analysis","text":"<ul> <li>Category breakdown with percentages</li> <li>Daily/monthly spending projections</li> <li>Budget status indicators (HEALTHY/WARNING/OVER_BUDGET)</li> <li>Trend detection</li> </ul>"},{"location":"#personalized-recommendations","title":"\ud83d\udca1 Personalized Recommendations","text":"<ul> <li>LLM-generated financial advice</li> <li>Prioritized action items (LOW/MEDIUM/HIGH/URGENT)</li> <li>Measurable financial goals</li> <li>Category-specific insights</li> </ul>"},{"location":"#system-architecture","title":"System Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Frontend (Streamlit)             \u2502\n\u2502         User Interface &amp; Visualization        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502 HTTP\n               \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Backend (FastAPI)                  \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502        Orchestrator Service            \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502        \u2502      \u2502      \u2502      \u2502                 \u2502\n\u2502    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u2502\n\u2502    \u2502Class \u2502 \u2502Search\u2502 \u2502Analy\u2502 \u2502Strategy \u2502      \u2502\n\u2502    \u2502-ifier\u2502 \u2502-er   \u2502 \u2502-st  \u2502 \u2502-st      \u2502      \u2502\n\u2502    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2502\n\u2502                                                \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u2502\n\u2502  \u2502LLM Service\u2502  \u2502Storage  \u2502  \u2502Tools     \u2502    \u2502\n\u2502  \u2502(Ollama)  \u2502  \u2502(JSON)   \u2502  \u2502(Search)  \u2502    \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"#technology-stack","title":"Technology Stack","text":""},{"location":"#backend","title":"Backend","text":"<ul> <li>Framework: FastAPI 0.115+</li> <li>LLM: Ollama (llama3.2:1b, llama3.2:3b)</li> <li>Search: DuckDuckGo (ddgs)</li> <li>Storage: JSON-based async file I/O (aiofiles)</li> <li>Logging: Loguru</li> <li>Security: RestrictedPython for code execution</li> </ul>"},{"location":"#frontend","title":"Frontend","text":"<ul> <li>Framework: Streamlit</li> <li>HTTP Client: httpx (async)</li> <li>Visualization: Plotly</li> </ul>"},{"location":"#infrastructure","title":"Infrastructure","text":"<ul> <li>Python: 3.11+</li> <li>Local LLM: Ollama</li> <li>Data Format: JSON</li> </ul>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>case-study-2-e/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 core/                 # Core infrastructure\n\u2502   \u2502   \u251c\u2500\u2500 config.py        # Configuration management\n\u2502   \u2502   \u251c\u2500\u2500 logger.py        # Logging setup\n\u2502   \u2502   \u2514\u2500\u2500 prompts.py       # LLM prompt templates\n\u2502   \u251c\u2500\u2500 agents/              # 4 AI agents\n\u2502   \u2502   \u251c\u2500\u2500 classifier.py    # Agent 1: Parse &amp; categorize\n\u2502   \u2502   \u251c\u2500\u2500 searcher.py      # Agent 2: Price research\n\u2502   \u2502   \u251c\u2500\u2500 analyst.py       # Agent 3: Financial metrics\n\u2502   \u2502   \u2514\u2500\u2500 strategist.py    # Agent 4: Recommendations\n\u2502   \u251c\u2500\u2500 api/                 # REST API\n\u2502   \u2502   \u251c\u2500\u2500 routes.py        # Endpoints\n\u2502   \u2502   \u2514\u2500\u2500 schemas.py       # Request/response models\n\u2502   \u251c\u2500\u2500 domain/              # Business domain\n\u2502   \u2502   \u251c\u2500\u2500 models.py        # Data entities\n\u2502   \u2502   \u2514\u2500\u2500 enums.py         # Enumerations\n\u2502   \u251c\u2500\u2500 services/            # Business logic\n\u2502   \u2502   \u251c\u2500\u2500 orchestrator.py  # Agent coordination\n\u2502   \u2502   \u251c\u2500\u2500 llm_service.py   # LLM management\n\u2502   \u2502   \u2514\u2500\u2500 storage.py       # Data persistence\n\u2502   \u251c\u2500\u2500 tools/               # Utility tools\n\u2502   \u2502   \u2514\u2500\u2500 search_tool.py   # Web search\n\u2502   \u251c\u2500\u2500 tests/               # Test suite (116+ tests)\n\u2502   \u2514\u2500\u2500 main.py             # Application entry\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 api/                # Backend client\n\u2502   \u251c\u2500\u2500 components/         # UI components\n\u2502   \u251c\u2500\u2500 utils/              # Utilities (styles, formatters)\n\u2502   \u251c\u2500\u2500 views/              # Page views\n\u2502   \u2514\u2500\u2500 app.py              # Streamlit app\n\u251c\u2500\u2500 docs/                   # Documentation\n\u2514\u2500\u2500 data/                   # Data storage\n</code></pre>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Architecture - System design and component details</li> <li>Agents - 4-agent pipeline documentation</li> <li>API - REST API endpoints and schemas</li> <li>Model Selection - Intelligent LLM routing strategy</li> </ul>"},{"location":"#core-concepts","title":"Core Concepts","text":""},{"location":"#multi-agent-workflow","title":"Multi-Agent Workflow","text":"<p>The system executes a 4-stage pipeline:</p> <ol> <li>Classifier \u2192 Parses raw text, extracts amounts, categorizes expenses</li> <li>Searcher \u2192 Researches market prices for high-value or unparsed items</li> <li>Analyst \u2192 Calculates metrics, determines budget status, detects trends</li> <li>Strategist \u2192 Generates personalized recommendations and action plans</li> </ol>"},{"location":"#data-flow","title":"Data Flow","text":"<pre><code>User Input \u2192 Classifier \u2192 Searcher \u2192 Analyst \u2192 Strategist \u2192 JSON Response\n   \u2193            \u2193           \u2193          \u2193          \u2193\n[Raw Text] [Expenses] [Enriched] [Analysis] [Recommendations]\n</code></pre>"},{"location":"#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li>Local LLM: Privacy-first, no API costs, full control</li> <li>Task-Based Model Selection: Performance optimization</li> <li>JSON Storage: Simple, portable, debuggable</li> <li>Async Architecture: Better throughput and resource utilization</li> <li>Modular Frontend: Clean separation, easy to maintain</li> </ol>"},{"location":"#performance-characteristics","title":"Performance Characteristics","text":"<ul> <li>Classification: ~2-3 seconds (fast model)</li> <li>Search: ~1-2 seconds per item (parallel)</li> <li>Analysis: &lt;1 second (no LLM, pure calculation)</li> <li>Recommendations: ~5-8 seconds (accurate model)</li> <li>Total Pipeline: ~10-15 seconds for 5-10 expenses</li> </ul>"},{"location":"#testing","title":"Testing","text":"<ul> <li>Unit Tests: 116+ tests covering all components</li> <li>Integration Tests: API endpoint testing</li> <li>Edge Cases: Invalid inputs, concurrent operations, security</li> <li>Coverage: Agents, services, tools, API, domain models</li> </ul>"},{"location":"#documentation-standards","title":"Documentation Standards","text":"<p>All backend code includes comprehensive English docstrings: - Classes: Purpose, features, attributes - Methods: Args, returns, raises, examples - Functions: Parameters, return values, side effects</p>"},{"location":"#license","title":"License","text":"<p>MIT License - See LICENSE file for details.</p>  <p>Last Updated: February 2026 Version: 1.0.0 Author: Case Study 2 - Multi-Agent Budget Analysis</p>"},{"location":"agents/","title":"Agent System","text":""},{"location":"agents/#overview","title":"Overview","text":"<p>The system uses 4 specialized agents that work in a coordinated pipeline to analyze expenses and generate recommendations. Each agent has a single responsibility and well-defined input/output contracts.</p>"},{"location":"agents/#multi-agent-architecture","title":"Multi-Agent Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                      ORCHESTRATOR                         \u2502\n\u2502            Coordinates Multi-Agent Workflow               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502          \u2502          \u2502          \u2502\n        \u2193          \u2193          \u2193          \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502Agent 1\u2502  \u2502Agent 2 \u2502  \u2502Agent 3\u2502  \u2502 Agent 4  \u2502\n    \u2502CLASS  \u2502  \u2502SEARCH  \u2502  \u2502ANALYZE\u2502  \u2502STRATEGY  \u2502\n    \u2502-IFIER \u2502  \u2502-ER     \u2502  \u2502 -ST   \u2502  \u2502 -ST      \u2502\n    \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502           \u2502          \u2502           \u2502\n        \u2193           \u2193          \u2193           \u2193\n   [Expenses]   [Metadata]  [Analysis]  [Recommendations]\n</code></pre>"},{"location":"agents/#agent-pipeline","title":"Agent Pipeline","text":""},{"location":"agents/#stage-1-classification","title":"Stage 1: Classification","text":"<p>Agent: Classifier Input: Raw expense texts Output: Parsed and categorized expenses Time: ~2-3 seconds</p>"},{"location":"agents/#stage-2-search-optional","title":"Stage 2: Search (Optional)","text":"<p>Agent: Searcher Input: Classified expenses Output: Expenses enriched with market data Time: ~1-2 seconds per item</p>"},{"location":"agents/#stage-3-analysis","title":"Stage 3: Analysis","text":"<p>Agent: Analyst Input: Expenses + optional income Output: Financial metrics and trends Time: &lt;1 second</p>"},{"location":"agents/#stage-4-strategy","title":"Stage 4: Strategy","text":"<p>Agent: Strategist Input: Analysis results Output: Recommendations and action plans Time: ~5-8 seconds</p>"},{"location":"agents/#agent-1-classifier","title":"Agent 1: Classifier","text":""},{"location":"agents/#purpose","title":"Purpose","text":"<p>Parses raw expense text and classifies into categories.</p>"},{"location":"agents/#responsibilities","title":"Responsibilities","text":"<ol> <li>Extract description and amount from text</li> <li>Categorize expense using keywords</li> <li>Handle parsing failures gracefully</li> </ol>"},{"location":"agents/#strategy","title":"Strategy","text":"<p>3-Tier Parsing: <pre><code>1. Regex (Fast)\n   \u251c\u2500 Success? \u2192 Return (description, amount)\n   \u2514\u2500 Fail? \u2192 Try LLM\n       \u251c\u2500 Success? \u2192 Return (description, amount)\n       \u2514\u2500 Fail? \u2192 Return (text, 0.0)  \u2190 Zero-amount fallback\n</code></pre></p>"},{"location":"agents/#implementation","title":"Implementation","text":"<pre><code>class ClassifierAgent(BaseAgent):\n    \"\"\"Expense classifier (Agent 1)\"\"\"\n\n    async def execute(self, expense_texts: list[str]) -&gt; list[Expense]:\n        \"\"\"Classify multiple expenses\"\"\"\n        expenses = []\n        for text in expense_texts:\n            expense = await self._classify_single(text)\n            expenses.append(expense)\n        return expenses\n\n    async def _classify_single(self, text: str) -&gt; Expense:\n        \"\"\"Classify single expense\"\"\"\n        # Parse: extract description and amount\n        description, amount = await self._parse(text)\n\n        # Categorize: assign category\n        category = await self._categorize(description)\n\n        return Expense(description=description, \n                      amount=amount, \n                      category=category)\n</code></pre>"},{"location":"agents/#parsing-logic","title":"Parsing Logic","text":"<p>Regex Pattern: <pre><code>pattern = r'^(.+?)\\s+(\\d+(?:[.,]\\d+)?)\\s*(TL|\u20ba|tl)\\s*$'\n# Matches: \"kahve 50 TL\", \"market al\u0131\u015fveri\u015fi 300.50 TL\"\n</code></pre></p> <p>LLM Fallback: <pre><code>prompt = \"\"\"Analyze this expense text: \"{text}\"\nReturn in JSON format:\n{\"description\": \"...\", \"amount\": 123.45}\"\"\"\n</code></pre></p> <p>Zero-Amount Fallback: - If both regex and LLM fail to parse amount - Returns <code>(text, 0.0)</code> to trigger Searcher agent - Example: \"laptop\" \u2192 (\"laptop\", 0.0)</p>"},{"location":"agents/#categorization","title":"Categorization","text":"<p>Keyword Matching: <pre><code>keywords_map = {\n    FOOD: [\"market\", \"yemek\", \"kahve\", \"restaurant\", ...],\n    TRANSPORT: [\"benzin\", \"taksi\", \"uber\", \"metro\", ...],\n    SHOPPING: [\"laptop\", \"telefon\", \"giyim\", ...],\n    # ... 10 categories total\n}\n</code></pre></p> <p>Examples: - \"starbucks kahve 50 TL\" \u2192 FOOD - \"uber taksi 120 TL\" \u2192 TRANSPORT - \"macbook pro\" \u2192 SHOPPING (zero-amount for Searcher)</p>"},{"location":"agents/#error-handling","title":"Error Handling","text":"<ul> <li>Invalid text \u2192 Logged and skipped</li> <li>Parsing failures \u2192 Zero-amount fallback</li> <li>Category mismatch \u2192 Defaults to OTHER</li> </ul>"},{"location":"agents/#agent-2-searcher","title":"Agent 2: Searcher","text":""},{"location":"agents/#purpose_1","title":"Purpose","text":"<p>Researches market prices for high-value or unparsed expenses via web search.</p>"},{"location":"agents/#responsibilities_1","title":"Responsibilities","text":"<ol> <li>Filter expenses that need price research</li> <li>Search DuckDuckGo for market prices</li> <li>Enrich expense metadata with search results</li> </ol>"},{"location":"agents/#when-to-search","title":"When to Search","text":"<p>Criteria: <pre><code>searchable = [\n    e for e in expenses \n    if e.amount &gt;= threshold OR e.amount == 0.0\n]\n</code></pre></p> <p>Examples: - <code>amount &gt;= 100 TL</code> \u2192 High-value item (laptop, rent) - <code>amount == 0.0</code> \u2192 Unparsed price (needs research)</p>"},{"location":"agents/#implementation_1","title":"Implementation","text":"<pre><code>class SearcherAgent(BaseAgent):\n    \"\"\"Price searcher (Agent 2)\"\"\"\n\n    def __init__(self, search_tool, threshold: float = 100.0):\n        self.search = search_tool\n        self.threshold = threshold\n\n    async def execute(self, expenses: list[Expense]) -&gt; list[Expense]:\n        \"\"\"Search for high-value/unparsed expenses\"\"\"\n        searchable = [\n            e for e in expenses \n            if e.amount &gt;= self.threshold or e.amount == 0.0\n        ]\n\n        for expense in searchable:\n            results = await self.search.search_product_price(\n                expense.description\n            )\n\n            if results:\n                expense.metadata[\"search_results\"] = results[:3]\n                expense.metadata[\"searched\"] = True\n\n        return expenses\n</code></pre>"},{"location":"agents/#search-strategy","title":"Search Strategy","text":"<p>Query Format: <pre><code>query = f\"{product_name} fiyat\"\n# Example: \"macbook pro fiyat\" \u2192 Turkish price results\n</code></pre></p> <p>Result Structure: <pre><code>{\n    \"title\": \"MacBook Pro M2 Fiyatlar\u0131\",\n    \"link\": \"https://...\",\n    \"snippet\": \"MacBook Pro 13-inch M2 chip 8GB RAM...\"\n}\n</code></pre></p> <p>Metadata Enrichment: <pre><code>expense.metadata = {\n    \"search_results\": [\n        {\"title\": \"...\", \"link\": \"...\", \"snippet\": \"...\"},\n        {\"title\": \"...\", \"link\": \"...\", \"snippet\": \"...\"},\n        {\"title\": \"...\", \"link\": \"...\", \"snippet\": \"...\"}\n    ],\n    \"searched\": True\n}\n</code></pre></p>"},{"location":"agents/#performance","title":"Performance","text":"<ul> <li>Parallel Search: Multiple items searched concurrently</li> <li>Limit Results: Top 3 results per item</li> <li>Timeout: 10 seconds per search</li> </ul>"},{"location":"agents/#agent-3-analyst","title":"Agent 3: Analyst","text":""},{"location":"agents/#purpose_2","title":"Purpose","text":"<p>Calculates financial metrics and determines budget health.</p>"},{"location":"agents/#responsibilities_2","title":"Responsibilities","text":"<ol> <li>Calculate total spending, averages, projections</li> <li>Break down spending by category</li> <li>Determine budget status</li> <li>Detect spending trends</li> </ol>"},{"location":"agents/#implementation_2","title":"Implementation","text":"<pre><code>class AnalystAgent(BaseAgent):\n    \"\"\"Budget analyst (Agent 3)\"\"\"\n\n    async def execute(\n        self,\n        expenses: list[Expense],\n        days_analyzed: int,\n        income: float = None\n    ) -&gt; Analysis:\n        \"\"\"Analyze expenses and generate metrics\"\"\"\n\n        # Basic calculations\n        total = sum(e.amount for e in expenses)\n        daily_rate = total / days_analyzed\n        monthly_projection = daily_rate * 30\n\n        # Category breakdown\n        category_totals = {}\n        for e in expenses:\n            cat = e.category.value\n            category_totals[cat] = category_totals.get(cat, 0) + e.amount\n\n        # Budget status\n        if income:\n            usage_pct = (monthly_projection / income) * 100\n            status = BudgetStatus.from_percentage(usage_pct)\n            remaining = income - monthly_projection\n        else:\n            status = BudgetStatus.UNKNOWN\n            remaining = None\n\n        # Trend detection\n        trends = self._detect_trends(category_totals, total)\n\n        return Analysis(\n            total_expenses=total,\n            daily_rate=daily_rate,\n            monthly_projection=monthly_projection,\n            category_breakdown=category_totals,\n            budget_status=status,\n            remaining_budget=remaining,\n            trends=trends\n        )\n</code></pre>"},{"location":"agents/#metrics","title":"Metrics","text":"<p>Core Calculations: <pre><code>total_spending = sum(expense.amount for expense in expenses)\ndaily_rate = total_spending / days_analyzed\nmonthly_projection = daily_rate * 30\n</code></pre></p> <p>Budget Status: <pre><code>usage_percentage = (monthly_projection / income) * 100\n\nif usage_percentage &lt; 80:     \u2192 HEALTHY\nelif usage_percentage &lt;= 100: \u2192 WARNING\nelse:                          \u2192 OVER_BUDGET\n</code></pre></p> <p>Category Breakdown: <pre><code>{\n    \"FOOD\": 450.0,      # 30% of total\n    \"TRANSPORT\": 300.0, # 20% of total\n    \"SHOPPING\": 750.0,  # 50% of total (HIGH!)\n    ...\n}\n</code></pre></p>"},{"location":"agents/#trend-detection","title":"Trend Detection","text":"<p>Logic: <pre><code>def _detect_trends(self, breakdown: dict, total: float) -&gt; list[str]:\n    \"\"\"Detect high-spending categories (\u226530%)\"\"\"\n    trends = []\n    for category, amount in breakdown.items():\n        percentage = (amount / total) * 100\n        if percentage &gt;= 30:\n            trends.append(\n                f\"{emoji} {category} spending is high \"\n                f\"({amount:.0f} TL, {percentage:.1f}%)\"\n            )\n    return trends\n</code></pre></p> <p>Example Output: <pre><code>\ud83d\udecd\ufe0f SHOPPING spending is high (750 TL, 50.0%)\n</code></pre></p>"},{"location":"agents/#performance_1","title":"Performance","text":"<ul> <li>No LLM calls: Pure calculation</li> <li>Instant: &lt;100ms execution time</li> <li>No external dependencies</li> </ul>"},{"location":"agents/#agent-4-strategist","title":"Agent 4: Strategist","text":""},{"location":"agents/#purpose_3","title":"Purpose","text":"<p>Generates personalized financial recommendations and action plans.</p>"},{"location":"agents/#responsibilities_3","title":"Responsibilities","text":"<ol> <li>Generate LLM-based recommendations</li> <li>Create prioritized action items</li> <li>Define financial goals with metrics</li> </ol>"},{"location":"agents/#implementation_3","title":"Implementation","text":"<pre><code>class StrategistAgent(BaseAgent):\n    \"\"\"Financial strategist (Agent 4)\"\"\"\n\n    async def execute(self, analysis: Analysis) -&gt; Recommendation:\n        \"\"\"Generate recommendations\"\"\"\n\n        # LLM recommendations\n        llm_text = await self._generate_llm_recommendations(analysis)\n        summary, recommendations = self._parse_response(llm_text)\n\n        # Rule-based action items\n        actions = self._generate_actions(analysis)\n\n        # Financial goals\n        goals = self._generate_goals(analysis)\n\n        return Recommendation(\n            summary=summary,\n            recommendations=recommendations,\n            action_items=actions,\n            goals=goals,\n            analysis_id=analysis.id\n        )\n</code></pre>"},{"location":"agents/#llm-recommendations","title":"LLM Recommendations","text":"<p>Prompt Template: <pre><code>\"\"\"Financial Status:\n\n\ud83d\udcca Basic Information:\n- Total Spending: {total} TL\n- Daily Average: {daily} TL\n- Monthly Projection: {monthly} TL\n\n\u2705 Status: {status}\n\ud83d\udcb0 Income: {income} TL\n\ud83d\udcca Usage: {usage_pct}%\n\n\ud83d\udcc1 Category Distribution:\n  - FOOD: 30.0%\n  - TRANSPORT: 20.0%\n  - SHOPPING: 50.0%\n\n\ud83d\udcc8 Trends:\n  - \ud83d\udecd\ufe0f SHOPPING spending is high (750 TL, 50.0%)\n\n---\n\nProvide:\n1. Status Summary (2-3 sentences)\n2. Recommendations (3-4 suggestions)\n3. Actions (prioritized to-dos)\n4. Goals (measurable objectives)\n\"\"\"\n</code></pre></p> <p>Model: Accurate model (llama3.2:3b) for complex reasoning</p>"},{"location":"agents/#rule-based-actions","title":"Rule-Based Actions","text":"<p>Status-Based Priority: <pre><code>def _generate_actions(self, analysis: Analysis) -&gt; list[ActionItem]:\n    \"\"\"Generate actions based on budget status\"\"\"\n\n    actions = []\n    status = analysis.budget_status\n\n    if status == BudgetStatus.HEALTHY:\n        actions.append(ActionItem(\n            description=\"Track your weekly expenses\",\n            priority=ActionPriority.LOW\n        ))\n\n    elif status == BudgetStatus.WARNING:\n        # Find highest spending category\n        top_category = max(analysis.category_breakdown.items(), \n                          key=lambda x: x[1])[0]\n        actions.append(ActionItem(\n            description=f\"Reduce {top_category} spending by 15%\",\n            priority=ActionPriority.MEDIUM,\n            potential_savings=analysis.category_breakdown[top_category] * 0.15\n        ))\n\n    elif status == BudgetStatus.OVER_BUDGET:\n        actions.append(ActionItem(\n            description=\"URGENT: Cut spending by 30%\",\n            priority=ActionPriority.URGENT\n        ))\n        actions.append(ActionItem(\n            description=\"Stop all non-essential spending\",\n            priority=ActionPriority.HIGH\n        ))\n\n    return actions\n</code></pre></p>"},{"location":"agents/#financial-goals","title":"Financial Goals","text":"<p>Goal Structure: <pre><code>@dataclass\nclass Goal:\n    description: str         # \"Daily spending target\"\n    current_value: float     # 150.0 (current daily rate)\n    target_value: float      # 100.0 (target daily rate)\n    timeframe: str          # \"7 days\"\n    category: Optional[str]  # \"SHOPPING\"\n</code></pre></p> <p>Examples: <pre><code>Goal(\n    description=\"Daily spending target\",\n    current_value=150.0,\n    target_value=100.0,\n    timeframe=\"7 days\"\n)\n\nGoal(\n    description=\"Reduce SHOPPING expenses\",\n    current_value=750.0,\n    target_value=500.0,\n    timeframe=\"30 days\",\n    category=\"SHOPPING\"\n)\n</code></pre></p>"},{"location":"agents/#response-parsing","title":"Response Parsing","text":"<p>LLM Output: <pre><code>Your budget is in WARNING status. You're at 85% usage.\n\n1. Reduce non-essential shopping expenses\n2. Set weekly spending limits\n3. Track daily expenses in a spreadsheet\n4. Find cheaper alternatives for recurring costs\n</code></pre></p> <p>Parsed Result: - Summary: \"Your budget is in WARNING status. You're at 85% usage.\" - Recommendations: List of 4 bullet points</p>"},{"location":"agents/#base-agent","title":"Base Agent","text":""},{"location":"agents/#abstract-base-class","title":"Abstract Base Class","text":"<pre><code>class BaseAgent(ABC):\n    \"\"\"Base class for all agents\"\"\"\n\n    def __init__(self, name: str):\n        self.name = name\n        self.logger = logger.bind(agent=name)\n\n    @property\n    @abstractmethod\n    def role(self) -&gt; str:\n        \"\"\"Agent role description\"\"\"\n        pass\n\n    @abstractmethod\n    async def execute(self, *args, **kwargs):\n        \"\"\"Execute agent's main task\"\"\"\n        pass\n\n    def log_start(self, task: str):\n        \"\"\"Log task start\"\"\"\n        self.logger.info(f\"\ud83d\ude80 {task}\")\n\n    def log_complete(self, task: str):\n        \"\"\"Log task completion\"\"\"\n        self.logger.info(f\"\u2705 {task}\")\n\n    def log_error(self, task: str, error: Exception):\n        \"\"\"Log error\"\"\"\n        self.logger.error(f\"\u274c {task}: {error}\")\n</code></pre>"},{"location":"agents/#benefits","title":"Benefits","text":"<ul> <li>Consistent logging across agents</li> <li>Template method pattern</li> <li>Easy to extend with new agents</li> </ul>"},{"location":"agents/#agent-communication","title":"Agent Communication","text":""},{"location":"agents/#data-contracts","title":"Data Contracts","text":"<p>Input/Output Types: <pre><code>Classifier:  list[str]      \u2192 list[Expense]\nSearcher:    list[Expense]  \u2192 list[Expense]\nAnalyst:     list[Expense]  \u2192 Analysis\nStrategist:  Analysis       \u2192 Recommendation\n</code></pre></p>"},{"location":"agents/#pipeline-flow","title":"Pipeline Flow","text":"<pre><code># Orchestrator.analyze_expenses()\nexpense_texts = [\"kahve 50 TL\", \"laptop\", ...]\n\n# Stage 1\nexpenses = await classifier.execute(expense_texts)\n# [Expense(desc=\"kahve\", amount=50, cat=FOOD),\n#  Expense(desc=\"laptop\", amount=0, cat=SHOPPING)]\n\n# Stage 2\nexpenses = await searcher.execute(expenses)\n# [Expense(..., metadata={}),\n#  Expense(..., metadata={\"search_results\": [...], \"searched\": True})]\n\n# Stage 3\nanalysis = await analyst.execute(expenses, days=7, income=15000)\n# Analysis(total=..., status=HEALTHY, trends=[...])\n\n# Stage 4\nrecommendation = await strategist.execute(analysis)\n# Recommendation(summary=\"...\", actions=[...], goals=[...])\n</code></pre>"},{"location":"agents/#performance-summary","title":"Performance Summary","text":"Agent Time LLM? External?     Classifier 2-3s \u2705 Fast \u274c   Searcher 1-2s per item \u274c \u2705 DuckDuckGo   Analyst &lt;1s \u274c \u274c   Strategist 5-8s \u2705 Accurate \u274c   Total 10-15s 2 calls Web search"},{"location":"agents/#error-handling_1","title":"Error Handling","text":""},{"location":"agents/#agent-level","title":"Agent-Level","text":"<ul> <li>Each agent logs errors independently</li> <li>Failures don't stop the pipeline</li> <li>Graceful degradation where possible</li> </ul>"},{"location":"agents/#examples","title":"Examples","text":"<ul> <li>Classifier fails \u2192 Skip expense</li> <li>Searcher fails \u2192 Continue without metadata</li> <li>Analyst fails \u2192 Return error to user</li> <li>Strategist fails \u2192 Return basic recommendations</li> </ul>  <p>Last Updated: February 2026 Agent System Version: 1.0.0</p>"},{"location":"api/","title":"API Documentation","text":""},{"location":"api/#overview","title":"Overview","text":"<p>ExpenseFlow exposes a RESTful API built with FastAPI. The API provides endpoints for health checking, expense analysis, and history retrieval.</p> <p>Base URL: <code>http://localhost:8000/api/v1</code></p>"},{"location":"api/#endpoints","title":"Endpoints","text":""},{"location":"api/#health-check","title":"Health Check","text":"<p>GET <code>/health</code></p> <p>Check API and Ollama service health.</p> <p>Response (200 OK): <pre><code>{\n  \"status\": \"healthy\",\n  \"ollama_available\": true,\n  \"timestamp\": \"2026-02-15T00:13:45.123456\"\n}\n</code></pre></p> <p>Status Values: - <code>healthy</code>: All services operational - <code>degraded</code>: API running but Ollama unavailable - <code>unhealthy</code>: Critical failure</p> <p>Example: <pre><code>curl http://localhost:8000/api/v1/health\n</code></pre></p>"},{"location":"api/#analyze-expenses","title":"Analyze Expenses","text":"<p>POST <code>/analyze</code></p> <p>Execute multi-agent workflow to analyze expenses.</p> <p>Request Body: <pre><code>{\n  \"expense_texts\": [\n    \"kahve 50 TL\",\n    \"market al\u0131\u015fveri\u015fi 300 TL\",\n    \"laptop\"\n  ],\n  \"income\": 15000.0,\n  \"days_analyzed\": 7,\n  \"enable_search\": true\n}\n</code></pre></p> <p>Request Schema: <pre><code>class AnalyzeRequest(BaseModel):\n    expense_texts: list[str]  # Required, min 1 item\n    income: Optional[float] = None  # Optional monthly income\n    days_analyzed: int = 1  # 1-365 days\n    enable_search: bool = True  # Enable web search\n</code></pre></p> <p>Response (200 OK): <pre><code>{\n  \"expenses\": [\n    {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n      \"text\": \"kahve\",\n      \"amount\": 50.0,\n      \"category\": \"FOOD\",\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440001\",\n      \"text\": \"market al\u0131\u015fveri\u015fi\",\n      \"amount\": 300.0,\n      \"category\": \"FOOD\",\n      \"metadata\": {}\n    },\n    {\n      \"id\": \"550e8400-e29b-41d4-a716-446655440002\",\n      \"text\": \"laptop\",\n      \"amount\": 0.0,\n      \"category\": \"SHOPPING\",\n      \"metadata\": {\n        \"search_results\": [\n          {\n            \"title\": \"MacBook Pro Fiyatlar\u0131 2026\",\n            \"link\": \"https://...\",\n            \"snippet\": \"MacBook Pro 13-inch M2...\"\n          }\n        ],\n        \"searched\": true\n      }\n    }\n  ],\n  \"analysis\": {\n    \"id\": \"660e8400-e29b-41d4-a716-446655440000\",\n    \"total_spent\": 350.0,\n    \"daily_rate\": 50.0,\n    \"monthly_projection\": 1500.0,\n    \"category_breakdown\": {\n      \"FOOD\": 350.0,\n      \"SHOPPING\": 0.0\n    },\n    \"budget_status\": \"HEALTHY\",\n    \"budget_percentage\": 10.0,\n    \"insights\": [\n      \"\ud83c\udf54 FOOD spending is high (350 TL, 100.0%)\"\n    ],\n    \"created_at\": \"2026-02-15T00:15:30.123456\"\n  },\n  \"recommendation\": {\n    \"summary\": \"Your budget is healthy. Continue tracking expenses.\",\n    \"actions\": [\n      {\n        \"description\": \"Track your weekly expenses\",\n        \"priority\": \"LOW\",\n        \"potential_savings\": null\n      }\n    ],\n    \"goals\": [\n      {\n        \"description\": \"Daily spending target\",\n        \"current_value\": 50.0,\n        \"target_value\": 45.0,\n        \"timeframe\": \"7 days\"\n      }\n    ]\n  },\n  \"processing_time_ms\": 12345.67\n}\n</code></pre></p> <p>Response Schema: <pre><code>class AnalyzeResponse(BaseModel):\n    expenses: list[ExpenseResponse]\n    analysis: AnalysisResponse\n    recommendation: RecommendationResponse\n    processing_time_ms: float\n</code></pre></p> <p>Error Responses:</p> <p>400 Bad Request - Invalid input: <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"expense_texts\"],\n      \"msg\": \"field required\",\n      \"type\": \"value_error.missing\"\n    }\n  ]\n}\n</code></pre></p> <p>500 Internal Server Error - Processing error: <pre><code>{\n  \"detail\": \"Analysis failed: No expenses were successfully classified\"\n}\n</code></pre></p> <p>Example: <pre><code>curl -X POST http://localhost:8000/api/v1/analyze \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"expense_texts\": [\"kahve 50 TL\", \"market 300 TL\"],\n    \"income\": 15000,\n    \"days_analyzed\": 7,\n    \"enable_search\": true\n  }'\n</code></pre></p>"},{"location":"api/#get-analysis-history","title":"Get Analysis History","text":"<p>GET <code>/analyses</code></p> <p>Retrieve all past analyses sorted by creation date (newest first).</p> <p>Response (200 OK): <pre><code>{\n  \"analyses\": [\n    {\n      \"id\": \"660e8400-e29b-41d4-a716-446655440000\",\n      \"total_spent\": 350.0,\n      \"daily_rate\": 50.0,\n      \"monthly_projection\": 1500.0,\n      \"category_breakdown\": {\n        \"FOOD\": 350.0\n      },\n      \"budget_status\": \"HEALTHY\",\n      \"budget_percentage\": 10.0,\n      \"insights\": [],\n      \"created_at\": \"2026-02-15T00:15:30.123456\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre></p> <p>Response Schema: <pre><code>class AnalysisListResponse(BaseModel):\n    analyses: list[AnalysisResponse]\n    total: int\n</code></pre></p> <p>Example: <pre><code>curl http://localhost:8000/api/v1/analyses\n</code></pre></p>"},{"location":"api/#data-models","title":"Data Models","text":""},{"location":"api/#expenseresponse","title":"ExpenseResponse","text":"<pre><code>class ExpenseResponse(BaseModel):\n    \"\"\"Single expense response\"\"\"\n    id: UUID\n    text: str\n    amount: float\n    category: str  # ExpenseCategory enum value\n    metadata: dict\n</code></pre> <p>Example: <pre><code>{\n  \"id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"text\": \"kahve\",\n  \"amount\": 50.0,\n  \"category\": \"FOOD\",\n  \"metadata\": {\n    \"searched\": false\n  }\n}\n</code></pre></p>"},{"location":"api/#analysisresponse","title":"AnalysisResponse","text":"<pre><code>class AnalysisResponse(BaseModel):\n    \"\"\"Financial analysis response\"\"\"\n    id: UUID\n    total_spent: float\n    daily_rate: float\n    monthly_projection: float\n    category_breakdown: dict[str, float]\n    budget_status: str  # BudgetStatus enum value\n    budget_percentage: float\n    insights: list[str]\n    created_at: datetime\n</code></pre> <p>Example: <pre><code>{\n  \"id\": \"660e8400-e29b-41d4-a716-446655440000\",\n  \"total_spent\": 1500.0,\n  \"daily_rate\": 214.29,\n  \"monthly_projection\": 6428.7,\n  \"category_breakdown\": {\n    \"FOOD\": 450.0,\n    \"TRANSPORT\": 300.0,\n    \"SHOPPING\": 750.0\n  },\n  \"budget_status\": \"HEALTHY\",\n  \"budget_percentage\": 42.86,\n  \"insights\": [\n    \"\ud83d\udecd\ufe0f SHOPPING spending is high (750 TL, 50.0%)\"\n  ],\n  \"created_at\": \"2026-02-15T00:15:30.123456\"\n}\n</code></pre></p>"},{"location":"api/#actionitemresponse","title":"ActionItemResponse","text":"<pre><code>class ActionItemResponse(BaseModel):\n    \"\"\"Action item response\"\"\"\n    description: str\n    priority: str  # ActionPriority enum value\n    potential_savings: Optional[float]\n</code></pre> <p>Example: <pre><code>{\n  \"description\": \"Reduce SHOPPING spending by 15%\",\n  \"priority\": \"MEDIUM\",\n  \"potential_savings\": 112.5\n}\n</code></pre></p> <p>Priority Values: - <code>LOW</code>: Optional improvements - <code>MEDIUM</code>: Should address soon - <code>HIGH</code>: Important, take action - <code>URGENT</code>: Critical, immediate action required</p>"},{"location":"api/#goalresponse","title":"GoalResponse","text":"<pre><code>class GoalResponse(BaseModel):\n    \"\"\"Financial goal response\"\"\"\n    description: str\n    current_value: float\n    target_value: float\n    timeframe: str\n</code></pre> <p>Example: <pre><code>{\n  \"description\": \"Daily spending target\",\n  \"current_value\": 214.29,\n  \"target_value\": 150.0,\n  \"timeframe\": \"7 days\"\n}\n</code></pre></p>"},{"location":"api/#recommendationresponse","title":"RecommendationResponse","text":"<pre><code>class RecommendationResponse(BaseModel):\n    \"\"\"Financial recommendations\"\"\"\n    summary: str\n    actions: list[ActionItemResponse]\n    goals: list[GoalResponse]\n</code></pre> <p>Example: <pre><code>{\n  \"summary\": \"Your budget is in WARNING status. Consider reducing expenses.\",\n  \"actions\": [\n    {\n      \"description\": \"Reduce SHOPPING spending by 15%\",\n      \"priority\": \"MEDIUM\",\n      \"potential_savings\": 112.5\n    }\n  ],\n  \"goals\": [\n    {\n      \"description\": \"Daily spending target\",\n      \"current_value\": 214.29,\n      \"target_value\": 150.0,\n      \"timeframe\": \"7 days\"\n    }\n  ]\n}\n</code></pre></p>"},{"location":"api/#enumerations","title":"Enumerations","text":""},{"location":"api/#expensecategory","title":"ExpenseCategory","text":"<p>Categories for expense classification:</p> <pre><code>class ExpenseCategory(str, Enum):\n    FOOD = \"FOOD\"              # \ud83c\udf54 Food, groceries, restaurants\n    TRANSPORT = \"TRANSPORT\"    # \ud83d\ude97 Transportation, fuel, taxi\n    UTILITIES = \"UTILITIES\"    # \ud83d\udca1 Bills, electricity, internet\n    ENTERTAINMENT = \"ENTERTAINMENT\"  # \ud83c\udfac Movies, entertainment\n    HEALTH = \"HEALTH\"          # \ud83c\udfe5 Healthcare, medicine\n    EDUCATION = \"EDUCATION\"    # \ud83d\udcda Education, books, courses\n    SHOPPING = \"SHOPPING\"      # \ud83d\udecd\ufe0f Shopping, electronics, clothing\n    HOUSING = \"HOUSING\"        # \ud83c\udfe0 Rent, housing costs\n    PERSONAL = \"PERSONAL\"      # \ud83d\udc87 Personal care, beauty\n    OTHER = \"OTHER\"            # \ud83d\udce6 Uncategorized\n</code></pre>"},{"location":"api/#budgetstatus","title":"BudgetStatus","text":"<p>Budget health indicators:</p> <pre><code>class BudgetStatus(str, Enum):\n    HEALTHY = \"HEALTHY\"        # \u2705 &lt; 80% of income spent\n    WARNING = \"WARNING\"        # \u26a0\ufe0f 80-100% of income spent\n    OVER_BUDGET = \"OVER_BUDGET\"  # \ud83d\udd34 &gt; 100% of income spent\n    UNKNOWN = \"UNKNOWN\"        # \u2753 No income provided\n</code></pre>"},{"location":"api/#actionpriority","title":"ActionPriority","text":"<p>Action urgency levels:</p> <pre><code>class ActionPriority(str, Enum):\n    LOW = \"LOW\"        # Optional improvements\n    MEDIUM = \"MEDIUM\"  # Should address soon\n    HIGH = \"HIGH\"      # Important, take action\n    URGENT = \"URGENT\"  # Critical, immediate action\n</code></pre>"},{"location":"api/#error-handling","title":"Error Handling","text":""},{"location":"api/#validation-errors-400","title":"Validation Errors (400)","text":"<p>Pydantic validation errors are automatically formatted:</p> <pre><code>{\n  \"detail\": [\n    {\n      \"loc\": [\"body\", \"days_analyzed\"],\n      \"msg\": \"ensure this value is less than or equal to 365\",\n      \"type\": \"value_error.number.not_le\"\n    }\n  ]\n}\n</code></pre>"},{"location":"api/#processing-errors-500","title":"Processing Errors (500)","text":"<p>Application errors return structured messages:</p> <pre><code>{\n  \"detail\": \"Analysis failed: [specific error message]\"\n}\n</code></pre> <p>Common Errors: - No expenses classified successfully - Ollama service unavailable - LLM generation timeout - Invalid expense format</p>"},{"location":"api/#rate-limiting","title":"Rate Limiting","text":"<p>Currently no rate limiting implemented. Recommended for production: - 60 requests per minute per IP - 10 analysis requests per minute per user</p>"},{"location":"api/#cors-configuration","title":"CORS Configuration","text":"<p>Development: <pre><code>allow_origins=[\"*\"]  # All origins allowed\n</code></pre></p> <p>Production (recommended): <pre><code>allow_origins=[\n    \"http://localhost:8501\",  # Streamlit frontend\n    \"https://yourdomain.com\"\n]\n</code></pre></p>"},{"location":"api/#openapi-documentation","title":"OpenAPI Documentation","text":"<p>Interactive API documentation available at:</p> <ul> <li>Swagger UI: <code>http://localhost:8000/docs</code></li> <li>ReDoc: <code>http://localhost:8000/redoc</code></li> <li>OpenAPI Schema: <code>http://localhost:8000/openapi.json</code></li> </ul>"},{"location":"api/#performance-characteristics","title":"Performance Characteristics","text":"Endpoint Avg Time Max Time Notes     <code>/health</code> 50ms 200ms Depends on Ollama ping   <code>/analyze</code> 10-15s 30s 5-10 expenses with search   <code>/analyses</code> 100ms 500ms Depends on history size    <p>Bottlenecks: - LLM generation (5-8s for recommendations) - Web search (1-2s per item) - Classification (2-3s total)</p>"},{"location":"api/#client-examples","title":"Client Examples","text":""},{"location":"api/#python-httpx","title":"Python (httpx)","text":"<pre><code>import httpx\n\nasync with httpx.AsyncClient() as client:\n    # Analyze expenses\n    response = await client.post(\n        \"http://localhost:8000/api/v1/analyze\",\n        json={\n            \"expense_texts\": [\"kahve 50 TL\", \"market 300 TL\"],\n            \"income\": 15000,\n            \"days_analyzed\": 7,\n            \"enable_search\": True\n        }\n    )\n    result = response.json()\n    print(f\"Total spent: {result['analysis']['total_spent']} TL\")\n</code></pre>"},{"location":"api/#javascript-fetch","title":"JavaScript (fetch)","text":"<pre><code>const response = await fetch('http://localhost:8000/api/v1/analyze', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json'\n  },\n  body: JSON.stringify({\n    expense_texts: ['kahve 50 TL', 'market 300 TL'],\n    income: 15000,\n    days_analyzed: 7,\n    enable_search: true\n  })\n});\n\nconst result = await response.json();\nconsole.log(`Total spent: ${result.analysis.total_spent} TL`);\n</code></pre>"},{"location":"api/#curl","title":"cURL","text":"<pre><code># Health check\ncurl http://localhost:8000/api/v1/health\n\n# Analyze\ncurl -X POST http://localhost:8000/api/v1/analyze \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"expense_texts\": [\"kahve 50 TL\"],\n    \"income\": 15000,\n    \"days_analyzed\": 7\n  }'\n\n# Get history\ncurl http://localhost:8000/api/v1/analyses\n</code></pre>"},{"location":"api/#authentication","title":"Authentication","text":"<p>Current: No authentication Production: Consider implementing: - API keys - JWT tokens - OAuth 2.0</p>"},{"location":"api/#versioning","title":"Versioning","text":"<p>API uses URL versioning: - Current: <code>/api/v1</code> - Future: <code>/api/v2</code> (breaking changes)</p>  <p>Last Updated: February 2026 API Version: 1.0.0</p>"},{"location":"architecture/","title":"System Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>ExpenseFlow implements a clean, modular architecture inspired by Domain-Driven Design principles, optimized for maintainability and clarity without over-engineering.</p>"},{"location":"architecture/#architectural-principles","title":"Architectural Principles","text":""},{"location":"architecture/#1-separation-of-concerns","title":"1. Separation of Concerns","text":"<ul> <li>Core: Infrastructure (config, logging, prompts)</li> <li>Domain: Business entities and logic</li> <li>Services: Application orchestration</li> <li>API: External interfaces</li> <li>Agents: Specialized AI workers</li> </ul>"},{"location":"architecture/#2-single-responsibility","title":"2. Single Responsibility","text":"<ul> <li>Each agent handles one specific task</li> <li>Each service manages one concern</li> <li>Clear boundaries between layers</li> </ul>"},{"location":"architecture/#3-dependency-injection","title":"3. Dependency Injection","text":"<ul> <li>Services receive dependencies via constructor</li> <li>Easy to test and mock</li> <li>Loose coupling</li> </ul>"},{"location":"architecture/#4-async-first","title":"4. Async-First","text":"<ul> <li>All I/O operations are async</li> <li>Better resource utilization</li> <li>Non-blocking execution</li> </ul>"},{"location":"architecture/#layer-architecture","title":"Layer Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   PRESENTATION LAYER                     \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502  Streamlit UI    \u2502     \u2502   FastAPI REST API \u2502       \u2502\n\u2502  \u2502  (frontend/)     \u2502\u2500\u2500\u2500\u2500\u25b6\u2502   (api/routes.py)  \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  APPLICATION LAYER                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502           Orchestrator Service                     \u2502 \u2502\n\u2502  \u2502  - Coordinates 4-agent pipeline                    \u2502 \u2502\n\u2502  \u2502  - Manages workflow execution                      \u2502 \u2502\n\u2502  \u2502  - Handles data persistence                        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                              \u2193                           \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 LLM Service  \u2502  \u2502   Storage    \u2502  \u2502 Search Tool  \u2502 \u2502\n\u2502  \u2502 (Ollama)     \u2502  \u2502   Service    \u2502  \u2502 (DuckDuckGo) \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    DOMAIN LAYER                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502              4 Specialized Agents                 \u2502  \u2502\n\u2502  \u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502  \u2502\n\u2502  \u2502  \u2502Classifier\u2502 \u2502Searcher \u2502 \u2502Analyst\u2502 \u2502Strategist\u2502 \u2502  \u2502\n\u2502  \u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502   Models     \u2502         \u2502       Enums             \u2502  \u2502\n\u2502  \u2502  - Expense   \u2502         \u2502  - ExpenseCategory      \u2502  \u2502\n\u2502  \u2502  - Analysis  \u2502         \u2502  - BudgetStatus         \u2502  \u2502\n\u2502  \u2502  - ActionItem\u2502         \u2502  - ActionPriority       \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                  INFRASTRUCTURE LAYER                    \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u2502\n\u2502  \u2502              Core Module (core/)                 \u2502   \u2502\n\u2502  \u2502  - config.py:  Environment configuration         \u2502   \u2502\n\u2502  \u2502  - logger.py:  Structured logging                \u2502   \u2502\n\u2502  \u2502  - prompts.py: LLM prompt templates              \u2502   \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"architecture/#component-deep-dive","title":"Component Deep Dive","text":""},{"location":"architecture/#core-module-backendcore","title":"Core Module (<code>backend/core/</code>)","text":"<p>Purpose: Centralized infrastructure and configuration</p> <p>Components: - <code>config.py</code>: Environment-based configuration using dataclasses - <code>logger.py</code>: Loguru setup with console + file outputs - <code>prompts.py</code>: LLM system prompts and templates</p> <p>Design:  - Single source of truth for configuration - No business logic - Imported by all other modules</p>"},{"location":"architecture/#domain-layer-backenddomain","title":"Domain Layer (<code>backend/domain/</code>)","text":"<p>Purpose: Business entities and core logic</p> <p>Models (<code>models.py</code>): <pre><code>@dataclass\nclass Expense:\n    \"\"\"Expense entity with category and metadata\"\"\"\n    description: str\n    amount: float\n    category: ExpenseCategory\n    metadata: dict\n    id: UUID\n    created_at: datetime\n\n@dataclass\nclass Analysis:\n    \"\"\"Financial analysis with metrics and budget status\"\"\"\n    total_expenses: float\n    daily_rate: float\n    monthly_projection: float\n    category_breakdown: dict\n    budget_status: BudgetStatus\n    trends: list[str]\n    # ... more fields\n\n@dataclass\nclass Recommendation:\n    \"\"\"Financial recommendations with action items\"\"\"\n    summary: str\n    recommendations: list[str]\n    action_items: list[ActionItem]\n    goals: list[Goal]\n</code></pre></p> <p>Enums (<code>enums.py</code>): - <code>ExpenseCategory</code>: 10 categories (FOOD, TRANSPORT, etc.) - <code>BudgetStatus</code>: HEALTHY, WARNING, OVER_BUDGET, UNKNOWN - <code>ActionPriority</code>: LOW, MEDIUM, HIGH, URGENT</p>"},{"location":"architecture/#agent-layer-backendagents","title":"Agent Layer (<code>backend/agents/</code>)","text":"<p>Purpose: Specialized AI workers</p> <p>Base Agent (<code>base_agent.py</code>): <pre><code>class BaseAgent(ABC):\n    \"\"\"Abstract base with logging helpers\"\"\"\n\n    @property\n    @abstractmethod\n    def role(self) -&gt; str:\n        \"\"\"Agent role description\"\"\"\n        pass\n\n    @abstractmethod\n    async def execute(self, *args, **kwargs):\n        \"\"\"Execute agent's main task\"\"\"\n        pass\n</code></pre></p> <p>4 Concrete Agents:</p> <ol> <li>Classifier (<code>classifier.py</code>)</li> <li>Input: Raw expense texts</li> <li>Output: Parsed and categorized Expense objects</li> <li> <p>Strategy: Regex \u2192 LLM fallback \u2192 Zero-amount fallback</p> </li> <li> <p>Searcher (<code>searcher.py</code>)</p> </li> <li>Input: List of expenses</li> <li>Output: Enriched expenses with search results</li> <li> <p>Strategy: Search items with amount \u2265 100 TL OR amount = 0.0</p> </li> <li> <p>Analyst (<code>analyst.py</code>)</p> </li> <li>Input: List of expenses + optional income</li> <li>Output: Analysis with metrics and trends</li> <li> <p>Strategy: Pure calculation, no LLM</p> </li> <li> <p>Strategist (<code>strategist.py</code>)</p> </li> <li>Input: Analysis object</li> <li>Output: Recommendation with action items and goals</li> <li>Strategy: LLM-generated advice + rule-based actions</li> </ol>"},{"location":"architecture/#service-layer-backendservices","title":"Service Layer (<code>backend/services/</code>)","text":"<p>Purpose: Application orchestration and business services</p> <p>Orchestrator (<code>orchestrator.py</code>): - Coordinates 4-agent pipeline - Manages workflow execution - Handles data persistence - Timing and logging</p> <p>LLM Service (<code>llm_service.py</code>): - Ollama HTTP client - Intelligent model selection - Task-type based routing - Health checking</p> <p>Storage Service (<code>storage.py</code>): - JSON-based persistence - Async file I/O (aiofiles) - Expense and analysis storage - History management</p>"},{"location":"architecture/#api-layer-backendapi","title":"API Layer (<code>backend/api/</code>)","text":"<p>Purpose: REST API interface</p> <p>Routes (<code>routes.py</code>): <pre><code>@router.get(\"/health\")\nasync def health_check():\n    \"\"\"Health check endpoint\"\"\"\n\n@router.post(\"/analyze\")\nasync def analyze_expenses(request: AnalyzeRequest):\n    \"\"\"Main analysis endpoint\"\"\"\n\n@router.get(\"/analyses\")\nasync def get_analyses():\n    \"\"\"Get analysis history\"\"\"\n</code></pre></p> <p>Schemas (<code>schemas.py</code>): - Pydantic models for request/response validation - Type safety and automatic documentation - OpenAPI schema generation</p>"},{"location":"architecture/#tools-layer-backendtools","title":"Tools Layer (<code>backend/tools/</code>)","text":"<p>Purpose: Utility tools for agents</p> <p>Search Tool (<code>search_tool.py</code>): - DuckDuckGo web search - Product price research - Turkish language support</p>"},{"location":"architecture/#data-flow","title":"Data Flow","text":""},{"location":"architecture/#complete-analysis-flow","title":"Complete Analysis Flow","text":"<pre><code>1. User Request\n   \u2193\n2. FastAPI receives POST /analyze\n   \u2193\n3. Orchestrator.analyze_expenses()\n   \u2193\n4. Agent 1: Classifier\n   - Parse text: \"kahve 50 TL\" \u2192 (\"kahve\", 50.0)\n   - Categorize: \"kahve\" \u2192 FOOD\n   - Create: Expense(description=\"kahve\", amount=50.0, category=FOOD)\n   \u2193\n5. Agent 2: Searcher (optional)\n   - Filter: expenses with amount \u2265 100 OR amount = 0\n   - Search: DuckDuckGo for market prices\n   - Enrich: Add search_results to metadata\n   \u2193\n6. Agent 3: Analyst\n   - Calculate: total, daily rate, monthly projection\n   - Breakdown: spending by category\n   - Status: determine HEALTHY/WARNING/OVER_BUDGET\n   - Trends: detect high-spending categories\n   \u2193\n7. Agent 4: Strategist\n   - Generate: LLM recommendations\n   - Create: Prioritized action items\n   - Define: Financial goals\n   \u2193\n8. Storage Service\n   - Save expenses to data/expenses.json\n   - Save analysis to data/analyses/analysis_{id}.json\n   \u2193\n9. Response\n   - Return complete analysis + recommendations\n   - Include processing time\n</code></pre>"},{"location":"architecture/#model-selection-flow","title":"Model Selection Flow","text":"<pre><code>Task Request\n   \u2193\nLLMService.select_model(task_type)\n   \u2193\n   \u251c\u2500 \"classify\" \u2192 Fast model (llama3.2:1b)\n   \u251c\u2500 \"search\" \u2192 Fast model\n   \u251c\u2500 \"analyze\" \u2192 Fast model\n   \u2514\u2500 \"recommend\" \u2192 Accurate model (llama3.2:3b)\n   \u2193\nOllama HTTP Request\n   \u2193\nResponse\n</code></pre>"},{"location":"architecture/#key-design-patterns","title":"Key Design Patterns","text":""},{"location":"architecture/#1-strategy-pattern","title":"1. Strategy Pattern","text":"<ul> <li>Different model selection strategies (auto/fast/accurate)</li> <li>Configurable via environment variables</li> </ul>"},{"location":"architecture/#2-template-method","title":"2. Template Method","text":"<ul> <li>BaseAgent defines workflow structure</li> <li>Concrete agents implement specific logic</li> </ul>"},{"location":"architecture/#3-facade-pattern","title":"3. Facade Pattern","text":"<ul> <li>Orchestrator provides simple interface to complex multi-agent system</li> </ul>"},{"location":"architecture/#4-repository-pattern","title":"4. Repository Pattern","text":"<ul> <li>StorageService abstracts data persistence</li> <li>Easy to swap JSON with database</li> </ul>"},{"location":"architecture/#5-dependency-injection","title":"5. Dependency Injection","text":"<ul> <li>Services injected via constructor</li> <li>Testable and mockable</li> </ul>"},{"location":"architecture/#configuration-management","title":"Configuration Management","text":""},{"location":"architecture/#environment-variables","title":"Environment Variables","text":"<pre><code># Ollama\nOLLAMA_BASE_URL=http://localhost:11434\nOLLAMA_FAST_MODEL=llama3.2:1b\nOLLAMA_ACCURATE_MODEL=llama3.2:3b\nOLLAMA_TIMEOUT=60\n\n# Model Strategy\nMODEL_STRATEGY=auto  # auto, fast, accurate\n\n# Agents\nENABLE_SEARCH_AGENT=true\nSEARCH_THRESHOLD=100.0\n\n# API\nAPI_HOST=0.0.0.0\nAPI_PORT=8000\nDEBUG=true\n\n# Storage\nDATA_DIR=data\nEXPENSES_FILE=data/expenses.json\nANALYSES_DIR=data/analyses\n\n# Logging\nLOG_LEVEL=INFO\nLOG_FILE=data/logs/app.log\n</code></pre>"},{"location":"architecture/#error-handling","title":"Error Handling","text":""},{"location":"architecture/#strategy","title":"Strategy","text":"<ol> <li>Validation Errors: Caught at API layer (Pydantic)</li> <li>LLM Errors: Fallback strategies (regex, zero-amount)</li> <li>Agent Errors: Logged but workflow continues where possible</li> <li>Critical Errors: Returned as HTTP 500 with error details</li> </ol>"},{"location":"architecture/#logging","title":"Logging","text":"<pre><code># Structured logging with loguru\nlogger.info(\"Starting analysis\")      # Info\nlogger.debug(\"Detailed context\")      # Debug\nlogger.warning(\"Potential issue\")     # Warning\nlogger.error(\"Error occurred\")        # Error\nlogger.bind(agent=\"Classifier\")       # Contextual\n</code></pre>"},{"location":"architecture/#testing-strategy","title":"Testing Strategy","text":""},{"location":"architecture/#test-coverage","title":"Test Coverage","text":"<ul> <li>Unit Tests: Individual components (agents, services, tools)</li> <li>Integration Tests: API endpoints, full workflow</li> <li>Edge Cases: Invalid inputs, timeouts, concurrent operations</li> <li>Security Tests: Code executor, input validation</li> </ul>"},{"location":"architecture/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 conftest.py           # Fixtures and setup\n\u251c\u2500\u2500 test_agents.py        # Agent unit tests\n\u251c\u2500\u2500 test_models.py        # Domain model tests\n\u251c\u2500\u2500 test_llm_service.py   # LLM service tests\n\u251c\u2500\u2500 test_storage.py       # Storage service tests\n\u251c\u2500\u2500 test_tools.py         # Tool tests\n\u2514\u2500\u2500 test_api_integration.py  # API integration tests\n</code></pre>"},{"location":"architecture/#performance-security","title":"Performance &amp; Security","text":""},{"location":"architecture/#optimization-strategies","title":"Optimization Strategies","text":"<ol> <li>Async I/O: Non-blocking file and network operations</li> <li>Model Selection: Fast models for simple tasks</li> <li>Parallel Search: Multiple searches concurrently</li> <li>Minimal LLM Calls: Use regex/rules where possible</li> </ol>"},{"location":"architecture/#security-measures","title":"Security Measures","text":"<ol> <li>Code Execution: RestrictedPython sandbox</li> <li>Input Validation: Pydantic schemas</li> <li>No File System Access: Restricted builtins</li> <li>Timeout Protection: All async operations</li> </ol>  <p>Last Updated: February 2026 Architecture Version: 1.0.0</p>"},{"location":"model-selection/","title":"Intelligent Model Selection","text":""},{"location":"model-selection/#overview","title":"Overview","text":"<p>One of the key innovations of this system is intelligent model selection - automatically choosing between fast and accurate LLM models based on task complexity. This provides the optimal balance between performance and quality.</p>"},{"location":"model-selection/#the-problem","title":"The Problem","text":""},{"location":"model-selection/#traditional-approach","title":"Traditional Approach","text":"<p>Most LLM applications use a single model for all tasks:</p> <p>Option 1: Large Model for Everything <pre><code>\u274c Slow: 20 tokens/sec\n\u274c Resource-intensive\n\u274c Wasteful for simple tasks\n\u2705 Good quality for complex tasks\n</code></pre></p> <p>Option 2: Small Model for Everything <pre><code>\u2705 Fast: 50 tokens/sec\n\u2705 Low resource usage\n\u274c Poor quality for complex reasoning\n\u274c Limited understanding\n</code></pre></p>"},{"location":"model-selection/#our-solution-task-based-selection","title":"Our Solution: Task-Based Selection","text":"<pre><code>\u2705 Fast model for simple tasks (classification, parsing)\n\u2705 Accurate model for complex tasks (recommendations)\n\u2705 3x faster overall performance\n\u2705 Better quality recommendations\n</code></pre>"},{"location":"model-selection/#model-inventory","title":"Model Inventory","text":""},{"location":"model-selection/#fast-model-llama321b","title":"Fast Model: <code>llama3.2:1b</code>","text":"<p>Specifications: - Size: 1 billion parameters - Speed: ~50 tokens/sec (CPU) - Memory: ~2GB RAM - Quantization: 4-bit</p> <p>Strengths: - \u26a1 Very fast inference - \ud83d\udcbe Low memory footprint - \ud83d\ude80 Instant responses - \ud83d\udcb0 Low resource cost</p> <p>Weaknesses: - \ud83e\udde0 Limited reasoning ability - \ud83d\udcdd Shorter context window - \ud83c\udfaf Less accurate on complex tasks</p> <p>Best For: - Text parsing (extract description and amount) - Category classification (keyword matching) - Simple extraction tasks - Data validation</p>"},{"location":"model-selection/#accurate-model-llama323b","title":"Accurate Model: <code>llama3.2:3b</code>","text":"<p>Specifications: - Size: 3 billion parameters - Speed: ~20 tokens/sec (CPU) - Memory: ~4GB RAM - Quantization: 4-bit</p> <p>Strengths: - \ud83e\udde0 Better reasoning and understanding - \ud83d\udcdd Nuanced, context-aware output - \ud83c\udfaf Higher accuracy on complex tasks - \ud83d\udcac More natural language</p> <p>Weaknesses: - \ud83d\udc0c Slower inference - \ud83d\udcbe Higher memory usage - \u23f1\ufe0f Longer response times</p> <p>Best For: - Financial recommendations - Strategic advice - Complex reasoning - Natural language generation</p>"},{"location":"model-selection/#selection-strategy","title":"Selection Strategy","text":""},{"location":"model-selection/#implementation","title":"Implementation","text":"<pre><code>class LLMService:\n    \"\"\"LLM service with intelligent model selection\"\"\"\n\n    def __init__(self):\n        self.fast_model = \"llama3.2:1b\"\n        self.accurate_model = \"llama3.2:3b\"\n        self.strategy = config.model_strategy  # auto, fast, accurate\n\n    def select_model(self, task_type: str) -&gt; str:\n        \"\"\"\n        Select model based on task complexity.\n\n        Args:\n            task_type: classify | search | analyze | recommend | general\n\n        Returns:\n            str: Model name to use\n        \"\"\"\n        # Force strategy (override)\n        if self.strategy == \"fast\":\n            return self.fast_model\n        if self.strategy == \"accurate\":\n            return self.accurate_model\n\n        # Auto strategy (intelligent selection)\n        if task_type in [\"classify\", \"search\", \"analyze\"]:\n            return self.fast_model  # Simple tasks\n        elif task_type == \"recommend\":\n            return self.accurate_model  # Complex reasoning\n        else:\n            return self.fast_model  # Default to fast for better UX\n</code></pre>"},{"location":"model-selection/#task-to-model-mapping","title":"Task-to-Model Mapping","text":"Task Type Model Reasoning     <code>classify</code> Fast (1b) Simple parsing and keyword matching   <code>search</code> Fast (1b) Query generation is straightforward   <code>analyze</code> Fast (1b) Mostly calculations, minimal LLM use   <code>recommend</code> Accurate (3b) Complex reasoning, nuanced advice   <code>general</code> Fast (1b) Default for better responsiveness"},{"location":"model-selection/#configuration","title":"Configuration","text":""},{"location":"model-selection/#environment-variables","title":"Environment Variables","text":"<pre><code># Model Configuration\nOLLAMA_FAST_MODEL=llama3.2:1b\nOLLAMA_ACCURATE_MODEL=llama3.2:3b\n\n# Selection Strategy\nMODEL_STRATEGY=auto  # Options: auto, fast, accurate\n</code></pre>"},{"location":"model-selection/#strategy-modes","title":"Strategy Modes","text":"<p>1. Auto (Default) <pre><code>MODEL_STRATEGY=auto\n</code></pre> - Intelligent task-based selection - Fast model for simple tasks - Accurate model for recommendations - Best for: Production use</p> <p>2. Fast <pre><code>MODEL_STRATEGY=fast\n</code></pre> - Always use fast model - Maximum speed - Lower quality recommendations - Best for: Development, testing, low-resource environments</p> <p>3. Accurate <pre><code>MODEL_STRATEGY=accurate\n</code></pre> - Always use accurate model - Best quality everywhere - Slower overall - Best for: Quality-critical scenarios, demonstrations</p>"},{"location":"model-selection/#performance-comparison","title":"Performance Comparison","text":""},{"location":"model-selection/#agent-performance-by-model","title":"Agent Performance by Model","text":"Agent Fast Model Accurate Model Speedup     Classifier 2s 6s 3x   Searcher N/A N/A -   Analyst 0.5s 0.5s 1x   Strategist 4s 8s 0.5x   Total ~6.5s ~14.5s 2.2x"},{"location":"model-selection/#with-intelligent-selection-auto","title":"With Intelligent Selection (Auto)","text":"Agent Model Used Time     Classifier Fast 2s   Searcher - 1-2s   Analyst - 0.5s   Strategist Accurate 8s   Total - ~11.5s    <p>Key Insight: We get 90% of accurate model quality with only 50% of the time cost!</p>"},{"location":"model-selection/#quality-vs-speed-trade-off","title":"Quality vs Speed Trade-off","text":""},{"location":"model-selection/#classification-task","title":"Classification Task","text":"<p>Fast Model (llama3.2:1b): <pre><code>Input: \"starbucks kahve 50 TL\"\nOutput: {\"description\": \"starbucks kahve\", \"amount\": 50.0}\nSuccess Rate: 95%\nTime: 2s\n</code></pre></p> <p>Accurate Model (llama3.2:3b): <pre><code>Input: \"starbucks kahve 50 TL\"\nOutput: {\"description\": \"starbucks kahve\", \"amount\": 50.0}\nSuccess Rate: 98%\nTime: 6s\n</code></pre></p> <p>Decision: 3% quality gain not worth 3x time cost \u2192 Use fast model</p>"},{"location":"model-selection/#recommendation-task","title":"Recommendation Task","text":"<p>Fast Model (llama3.2:1b): <pre><code>Output: \"Save money. Track expenses.\"\nQuality: Generic, not personalized\nTime: 4s\n</code></pre></p> <p>Accurate Model (llama3.2:3b): <pre><code>Output: \"Your SHOPPING spending is 50% of total. Consider:\n1. Set a weekly SHOPPING budget of 250 TL\n2. Compare prices before purchases\n3. Wait 24 hours before non-essential buys\"\nQuality: Detailed, actionable, personalized\nTime: 8s\n</code></pre></p> <p>Decision: 2x time cost worth it for much better advice \u2192 Use accurate model</p>"},{"location":"model-selection/#business-impact","title":"Business Impact","text":""},{"location":"model-selection/#user-experience","title":"User Experience","text":"<p>With Intelligent Selection: <pre><code>Total Time: 10-15 seconds\nUser Perception: \"Fast and smart\"\nQuality: High where it matters\n</code></pre></p> <p>Without (All Accurate): <pre><code>Total Time: 20-25 seconds\nUser Perception: \"Slow\"\nQuality: Marginally better classification\n</code></pre></p> <p>Without (All Fast): <pre><code>Total Time: 6-8 seconds\nUser Perception: \"Fast but generic\"\nQuality: Poor recommendations\n</code></pre></p>"},{"location":"model-selection/#cost-efficiency","title":"Cost Efficiency","text":"<p>Ollama (Local): - No API costs - Resource usage: CPU/RAM - Fast model: 2GB RAM - Accurate model: 4GB RAM</p> <p>If Using Cloud API (Hypothetical): - Fast model: $0.001 per 1K tokens - Accurate model: $0.005 per 1K tokens - Smart selection saves 60% on token costs</p>"},{"location":"model-selection/#implementation-details","title":"Implementation Details","text":""},{"location":"model-selection/#model-loading","title":"Model Loading","text":"<p>Models are loaded on-demand by Ollama:</p> <pre><code>async def generate(self, prompt: str, task_type: str = \"general\"):\n    \"\"\"Generate completion with selected model\"\"\"\n\n    # Select model\n    model = self.select_model(task_type)\n\n    # Ollama request\n    payload = {\n        \"model\": model,\n        \"prompt\": prompt,\n        \"stream\": False\n    }\n\n    response = await self._client.post(\"/api/generate\", json=payload)\n    return response.json()[\"response\"]\n</code></pre>"},{"location":"model-selection/#caching","title":"Caching","text":"<p>Ollama automatically caches loaded models: - First call: Model loading time (~2-5s) - Subsequent calls: Instant model access - Models stay in memory until RAM pressure</p>"},{"location":"model-selection/#testing","title":"Testing","text":""},{"location":"model-selection/#model-selection-tests","title":"Model Selection Tests","text":"<pre><code>def test_model_selection_strategy():\n    \"\"\"Test intelligent model selection\"\"\"\n    llm = LLMService()\n\n    # Simple tasks \u2192 Fast model\n    assert llm.select_model(\"classify\") == \"llama3.2:1b\"\n    assert llm.select_model(\"search\") == \"llama3.2:1b\"\n    assert llm.select_model(\"analyze\") == \"llama3.2:1b\"\n\n    # Complex tasks \u2192 Accurate model\n    assert llm.select_model(\"recommend\") == \"llama3.2:3b\"\n\n    # Unknown tasks \u2192 Fast model (default)\n    assert llm.select_model(\"unknown\") == \"llama3.2:1b\"\n\ndef test_forced_strategy():\n    \"\"\"Test forced strategy modes\"\"\"\n\n    # Force fast\n    os.environ[\"MODEL_STRATEGY\"] = \"fast\"\n    llm = LLMService()\n    assert llm.select_model(\"recommend\") == \"llama3.2:1b\"\n\n    # Force accurate\n    os.environ[\"MODEL_STRATEGY\"] = \"accurate\"\n    llm = LLMService()\n    assert llm.select_model(\"classify\") == \"llama3.2:3b\"\n</code></pre>"},{"location":"model-selection/#monitoring","title":"Monitoring","text":""},{"location":"model-selection/#metrics-to-track","title":"Metrics to Track","text":"<ol> <li>Model Usage:</li> <li>Fast model call count</li> <li>Accurate model call count</li> <li> <p>Total tokens per model</p> </li> <li> <p>Performance:</p> </li> <li>Average latency per model</li> <li>95th percentile latency</li> <li> <p>Cache hit rate</p> </li> <li> <p>Quality:</p> </li> <li>Classification accuracy</li> <li>Recommendation relevance score</li> <li>User satisfaction ratings</li> </ol>"},{"location":"model-selection/#logging","title":"Logging","text":"<pre><code>logger.info(f\"Model selection: task={task_type} \u2192 {model}\")\nlogger.debug(f\"Generating: model={model}, task={task_type}, tokens={len(prompt)}\")\n</code></pre>"},{"location":"model-selection/#future-improvements","title":"Future Improvements","text":""},{"location":"model-selection/#1-dynamic-threshold","title":"1. Dynamic Threshold","text":"<p>Adjust selection based on load: <pre><code>if system_load &gt; 80%:\n    # Use fast model even for complex tasks\n    return self.fast_model\n</code></pre></p>"},{"location":"model-selection/#2-quality-feedback-loop","title":"2. Quality Feedback Loop","text":"<p>Learn from user feedback: <pre><code>if user_rated_low:\n    # Switch to accurate model for this user\n    user_preferences[user_id] = \"accurate\"\n</code></pre></p>"},{"location":"model-selection/#3-multi-model-ensemble","title":"3. Multi-Model Ensemble","text":"<p>Combine models for best results: <pre><code># Fast model for initial analysis\ndraft = fast_model.generate(prompt)\n\n# Accurate model for refinement\nfinal = accurate_model.refine(draft)\n</code></pre></p>"},{"location":"model-selection/#4-speculative-decoding","title":"4. Speculative Decoding","text":"<p>Run both models in parallel: <pre><code># Start fast model immediately\nfast_future = fast_model.generate_async(prompt)\n\n# If fast model uncertain, use accurate model\nif fast_confidence &lt; 0.8:\n    return accurate_model.generate(prompt)\n</code></pre></p>"},{"location":"model-selection/#alternative-models","title":"Alternative Models","text":""},{"location":"model-selection/#if-using-different-sizes","title":"If Using Different Sizes","text":"<p>Tiny (0.5B - 1B): - Classification, parsing - Ultra-fast responses - Very low resource usage</p> <p>Small (3B - 7B): - General purpose - Good balance - Moderate resources</p> <p>Medium (13B - 30B): - High quality - Complex reasoning - High resource usage</p> <p>Large (70B+): - Best quality - Requires GPU - Not practical for this use case</p>"},{"location":"model-selection/#recommended-alternatives","title":"Recommended Alternatives","text":"<pre><code># Option 1: Lighter\nOLLAMA_FAST_MODEL=tinyllama:1.1b\nOLLAMA_ACCURATE_MODEL=llama3.2:3b\n\n# Option 2: Higher Quality\nOLLAMA_FAST_MODEL=llama3.2:3b\nOLLAMA_ACCURATE_MODEL=mistral:7b\n\n# Option 3: Production (GPU)\nOLLAMA_FAST_MODEL=llama3.2:3b\nOLLAMA_ACCURATE_MODEL=llama3:8b\n</code></pre>"},{"location":"model-selection/#key-takeaways","title":"Key Takeaways","text":"<ol> <li>Task-based selection beats one-size-fits-all</li> <li>Simple tasks don't need powerful models</li> <li>Complex reasoning benefits from larger models</li> <li>3x speedup with minimal quality trade-off</li> <li>Configurable strategy for different scenarios</li> <li>Easy to extend with new models or strategies</li> </ol>  <p>Last Updated: February 2026 Model Selection Version: 1.0.0</p>"}]}