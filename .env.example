# ==================== OLLAMA CONFIGURATION ====================
# Ollama server URL
OLLAMA_BASE_URL=http://localhost:11434

# Model selection
OLLAMA_FAST_MODEL=llama3.2:3b
OLLAMA_ACCURATE_MODEL=llama3.2:3b

# Request timeout (seconds)
OLLAMA_TIMEOUT=60

# ==================== MODEL SELECTION STRATEGY ====================
# Options: auto, fast, accurate
# - auto: Intelligent selection based on task type (recommended)
# - fast: Always use fast model
# - accurate: Always use accurate model
MODEL_STRATEGY=auto

# ==================== AGENT CONFIGURATION ====================
# Enable/disable search agent for web price research
ENABLE_SEARCH_AGENT=true

# Minimum amount (TL) to trigger web search
SEARCH_THRESHOLD=100.0

# Enable/disable code executor for dynamic calculations
ENABLE_CODE_EXECUTOR=true

# ==================== API SETTINGS ====================
# API host (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)
API_HOST=0.0.0.0

# API port
API_PORT=8000

# Debug mode (verbose logging, auto-reload)
DEBUG=true

# ==================== LOGGING ====================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log file path (relative to backend directory)
LOG_FILE=../data/logs/app.log

# ==================== STORAGE ====================
# Data directory (relative to backend directory)
DATA_DIR=../data

# Expenses file path
EXPENSES_FILE=../data/expenses.json

# Analyses directory
ANALYSES_DIR=../data/analyses
